{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO1ZNueLp9ac6huNuIuxa0n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jlessuk/Data_Bias_Perspecitve_Toxicity/blob/main/Data_Bias_jdl4758.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xP8ypXGQX_pP",
        "outputId": "4c2b8afa-4486-42e9-ec6b-520c529219f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Case\n",
            "0\n",
            "{'attributeScores': {'TOXICITY': {'spanScores': [{'begin': 0, 'end': 12, 'score': {'value': 0.75208336, 'type': 'PROBABILITY'}}], 'summaryScore': {'value': 0.75208336, 'type': 'PROBABILITY'}}}, 'languages': ['en'], 'detectedLanguages': ['en']}\n",
            "{'attributeScores': {'TOXICITY': {'spanScores': [{'begin': 0, 'end': 70, 'score': {'value': 0.39441586, 'type': 'PROBABILITY'}}], 'summaryScore': {'value': 0.39441586, 'type': 'PROBABILITY'}}}, 'languages': ['en'], 'detectedLanguages': ['en']}\n",
            "Case\n",
            "1\n",
            "{'attributeScores': {'TOXICITY': {'spanScores': [{'begin': 0, 'end': 12, 'score': {'value': 0.83334327, 'type': 'PROBABILITY'}}], 'summaryScore': {'value': 0.83334327, 'type': 'PROBABILITY'}}}, 'languages': ['en'], 'detectedLanguages': ['en']}\n",
            "{'attributeScores': {'TOXICITY': {'spanScores': [{'begin': 0, 'end': 69, 'score': {'value': 0.4826145, 'type': 'PROBABILITY'}}], 'summaryScore': {'value': 0.4826145, 'type': 'PROBABILITY'}}}, 'languages': ['en'], 'detectedLanguages': ['en']}\n",
            "Case\n",
            "2\n",
            "{'attributeScores': {'TOXICITY': {'spanScores': [{'begin': 0, 'end': 12, 'score': {'value': 0.83334327, 'type': 'PROBABILITY'}}], 'summaryScore': {'value': 0.83334327, 'type': 'PROBABILITY'}}}, 'languages': ['en'], 'detectedLanguages': ['en']}\n",
            "{'attributeScores': {'TOXICITY': {'spanScores': [{'begin': 0, 'end': 77, 'score': {'value': 0.4269174, 'type': 'PROBABILITY'}}], 'summaryScore': {'value': 0.4269174, 'type': 'PROBABILITY'}}}, 'languages': ['en'], 'detectedLanguages': ['en']}\n",
            "Case\n",
            "3\n",
            "{'attributeScores': {'TOXICITY': {'spanScores': [{'begin': 0, 'end': 19, 'score': {'value': 0.24603334, 'type': 'PROBABILITY'}}], 'summaryScore': {'value': 0.24603334, 'type': 'PROBABILITY'}}}, 'languages': ['en'], 'detectedLanguages': ['en']}\n",
            "{'attributeScores': {'TOXICITY': {'spanScores': [{'begin': 0, 'end': 42, 'score': {'value': 0.14256015, 'type': 'PROBABILITY'}}], 'summaryScore': {'value': 0.14256015, 'type': 'PROBABILITY'}}}, 'languages': ['en'], 'detectedLanguages': ['en']}\n",
            "Case\n",
            "4\n",
            "{'attributeScores': {'TOXICITY': {'spanScores': [{'begin': 0, 'end': 17, 'score': {'value': 0.78711975, 'type': 'PROBABILITY'}}], 'summaryScore': {'value': 0.78711975, 'type': 'PROBABILITY'}}}, 'languages': ['en'], 'detectedLanguages': ['en']}\n",
            "{'attributeScores': {'TOXICITY': {'spanScores': [{'begin': 0, 'end': 57, 'score': {'value': 0.40336934, 'type': 'PROBABILITY'}}], 'summaryScore': {'value': 0.40336934, 'type': 'PROBABILITY'}}}, 'languages': ['en'], 'detectedLanguages': ['en']}\n",
            "Case\n",
            "5\n",
            "{'attributeScores': {'TOXICITY': {'spanScores': [{'begin': 0, 'end': 16, 'score': {'value': 0.9248995, 'type': 'PROBABILITY'}}], 'summaryScore': {'value': 0.9248995, 'type': 'PROBABILITY'}}}, 'languages': ['en'], 'detectedLanguages': ['en']}\n",
            "{'attributeScores': {'TOXICITY': {'spanScores': [{'begin': 0, 'end': 65, 'score': {'value': 0.8696708, 'type': 'PROBABILITY'}}], 'summaryScore': {'value': 0.8696708, 'type': 'PROBABILITY'}}}, 'languages': ['en'], 'detectedLanguages': ['en']}\n",
            "Case\n",
            "6\n",
            "{'attributeScores': {'TOXICITY': {'spanScores': [{'begin': 0, 'end': 14, 'score': {'value': 0.45921504, 'type': 'PROBABILITY'}}], 'summaryScore': {'value': 0.45921504, 'type': 'PROBABILITY'}}}, 'languages': ['en'], 'detectedLanguages': ['en']}\n",
            "{'attributeScores': {'TOXICITY': {'spanScores': [{'begin': 0, 'end': 36, 'score': {'value': 0.17111848, 'type': 'PROBABILITY'}}], 'summaryScore': {'value': 0.17111848, 'type': 'PROBABILITY'}}}, 'languages': ['en'], 'detectedLanguages': ['en']}\n",
            "Case\n",
            "7\n",
            "{'attributeScores': {'TOXICITY': {'spanScores': [{'begin': 0, 'end': 12, 'score': {'value': 0.83334327, 'type': 'PROBABILITY'}}], 'summaryScore': {'value': 0.83334327, 'type': 'PROBABILITY'}}}, 'languages': ['en'], 'detectedLanguages': ['en']}\n",
            "{'attributeScores': {'TOXICITY': {'spanScores': [{'begin': 0, 'end': 84, 'score': {'value': 0.88599813, 'type': 'PROBABILITY'}}], 'summaryScore': {'value': 0.88599813, 'type': 'PROBABILITY'}}}, 'languages': ['en'], 'detectedLanguages': ['en']}\n",
            "Case\n",
            "8\n",
            "{'attributeScores': {'TOXICITY': {'spanScores': [{'begin': 0, 'end': 25, 'score': {'value': 0.31963667, 'type': 'PROBABILITY'}}], 'summaryScore': {'value': 0.31963667, 'type': 'PROBABILITY'}}}, 'languages': ['en'], 'detectedLanguages': ['en']}\n",
            "{'attributeScores': {'TOXICITY': {'spanScores': [{'begin': 0, 'end': 33, 'score': {'value': 0.22579013, 'type': 'PROBABILITY'}}], 'summaryScore': {'value': 0.22579013, 'type': 'PROBABILITY'}}}, 'languages': ['en'], 'detectedLanguages': ['en']}\n",
            "Case\n",
            "9\n",
            "{'attributeScores': {'TOXICITY': {'spanScores': [{'begin': 0, 'end': 18, 'score': {'value': 0.47119883, 'type': 'PROBABILITY'}}], 'summaryScore': {'value': 0.47119883, 'type': 'PROBABILITY'}}}, 'languages': ['en'], 'detectedLanguages': ['en']}\n",
            "{'attributeScores': {'TOXICITY': {'spanScores': [{'begin': 0, 'end': 48, 'score': {'value': 0.31686464, 'type': 'PROBABILITY'}}], 'summaryScore': {'value': 0.31686464, 'type': 'PROBABILITY'}}}, 'languages': ['en'], 'detectedLanguages': ['en']}\n"
          ]
        }
      ],
      "source": [
        "from googleapiclient import discovery\n",
        "import json\n",
        "\n",
        "def run_API(comment_text):\n",
        "  API_KEY = 'AIzaSyDbvXDpRQ4lf-_kpDo_0DDxkPCagVY5mzE'\n",
        "\n",
        "  client = discovery.build(\n",
        "    \"commentanalyzer\",\n",
        "    \"v1alpha1\",\n",
        "    developerKey=API_KEY,\n",
        "    discoveryServiceUrl=\"https://commentanalyzer.googleapis.com/$discovery/rest?version=v1alpha1\",\n",
        "    static_discovery=False,\n",
        "  )\n",
        "\n",
        "  analyze_request = {\n",
        "    'comment': {'text' : comment_text},\n",
        "    'requestedAttributes': {'TOXICITY': {}}\n",
        "  }\n",
        "\n",
        "  response = client.comments().analyze(body=analyze_request).execute()\n",
        "  print(response)\n",
        "\n",
        "\n",
        "insults = []\n",
        "creative_insults = []\n",
        "\n",
        "insult0 = \"You are ugly\"\n",
        "insult1 = \"You are dumb\"\n",
        "insult2 = \"You are dumb\"\n",
        "insult3 = \"You eat unhealthily\"\n",
        "insult4 = \"Your face is ugly\"\n",
        "insult5 = \"You are an idiot\"\n",
        "insult6 = \"You are boring\"\n",
        "insult7 = \"You are dumb\"\n",
        "insult8 = \"I wish I didn't know you.\"\n",
        "insult9 = \"You are not useful\"\n",
        "\n",
        "creative_insult0 = \"I might be fat but you look like something God drew with his left hand\"\n",
        "creative_insult1 = \"If brains were dynamite you wouldn’t have enough to blow your hat off\"\n",
        "creative_insult2 = \"You aren't the dumbest person in the world but you better hope they don't die\"\n",
        "creative_insult3 = \"You eat like we have free health insurance\"\n",
        "creative_insult4 = \"Your face looks like something I’d draw with my left hand\"\n",
        "creative_insult5 = \"You have your entire life to be an idiot. Why not take today off?\"\n",
        "creative_insult6 = \"If you were a spice, you'd be flour.\"\n",
        "creative_insult7 = \"He's so stupid he could count his balls three times and get three different numbers.\"\n",
        "creative_insult8 = \"I envy people who don’t know you.\"\n",
        "creative_insult9 = \"You’re about as useful as Anne Frank’s drum set.\"\n",
        "\n",
        "insults.extend((insult0, insult1, insult2, insult3, insult4, insult5, insult6, insult7, insult8, insult9))\n",
        "creative_insults.extend((creative_insult0, creative_insult1, creative_insult2, creative_insult3, creative_insult4, creative_insult5, creative_insult6, creative_insult7, creative_insult8, creative_insult9))\n",
        "\n",
        "x = 0\n",
        "while x < 10:\n",
        "  print(\"Case\")\n",
        "  print(x)\n",
        "  insult = insults[x]\n",
        "  creative_insult = creative_insults[x]\n",
        "  run_API(insult)\n",
        "  run_API(creative_insult)\n",
        "  x = x + 1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hypothesis:\n",
        "\n",
        "The model will have a more difficult time identifying clever insults than direct ones.\n",
        "\n",
        "Findings:\n",
        "\n",
        "I ran the API on 20 different prompts (10 pairs of two prompts). Each pair included a clever perosnal insult that I found online (reddit) and a simple insult with the same underlying meaning. Each pair of insults should represent approximately the same level of toxicity, because they have the same meaning.\n",
        "\n",
        "I found that the model consistenly identifies the clever insults as less toxic than the direct ones. In particular, the model struggles to identify a toxic statment as toxic when no insulting language is used. For example, the statment: \"If brains were dynamite you wouldn’t have enough to blow your hat off\" was rated as non-toxic. Its counterpart: \"You are dumb\" was rated as very toxic. This clearly represents a flaw in the model.\n",
        "\n",
        "Clearly, this API is effective but also quite limited/simple. It does not/cannot read the inputs in a logical way, and probably tends to analyze the words one at a time and give them an idividual score for toxicity based on their definitions.\n"
      ],
      "metadata": {
        "id": "GvW_JSCLH136"
      }
    }
  ]
}